{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"categories.json\",\"r\") as fp:\n",
    "    categories = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode event label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each event has single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 0]]\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_fake_singleLabel.json\",\"r\") as fp:\n",
    "    train = json.load(fp)\n",
    "x = [event['text'] for event in train]\n",
    "y = [event['category'] for event in train]\n",
    "print train_y\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(encoded_y)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each event has multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'concerts', u'art'], [u'art']]\n",
      "[[1 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_fake_multiLabel.json\",\"r\") as fp:\n",
    "    train = json.load(fp)\n",
    "x = [event['text'] for event in train]\n",
    "y = [event['category'] for event in train]\n",
    "print y\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize event text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "x = pad_sequences(sequences, maxlen=180, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_length = 300\n",
    "max_words = 5000\n",
    "num_classes = len(y[0])\n",
    "maxlen = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 180, 20)           100000    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 180, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 178, 300)          18300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 602       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 118,902\n",
      "Trainable params: 118,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6 samples, validate on 1 samples\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 1s 187ms/step - loss: 0.6861 - categorical_accuracy: 1.0000 - val_loss: 0.6643 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6659 - categorical_accuracy: 1.0000 - val_loss: 0.6435 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6468 - categorical_accuracy: 1.0000 - val_loss: 0.6232 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6272 - categorical_accuracy: 1.0000 - val_loss: 0.6034 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6073 - categorical_accuracy: 1.0000 - val_loss: 0.5840 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5890 - categorical_accuracy: 1.0000 - val_loss: 0.5655 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5693 - categorical_accuracy: 1.0000 - val_loss: 0.5466 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5513 - categorical_accuracy: 1.0000 - val_loss: 0.5277 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5327 - categorical_accuracy: 1.0000 - val_loss: 0.5089 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5126 - categorical_accuracy: 1.0000 - val_loss: 0.4899 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4930 - categorical_accuracy: 1.0000 - val_loss: 0.4708 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4752 - categorical_accuracy: 1.0000 - val_loss: 0.4518 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4561 - categorical_accuracy: 1.0000 - val_loss: 0.4328 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4353 - categorical_accuracy: 1.0000 - val_loss: 0.4139 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4177 - categorical_accuracy: 1.0000 - val_loss: 0.3952 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3945 - categorical_accuracy: 1.0000 - val_loss: 0.3765 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3751 - categorical_accuracy: 1.0000 - val_loss: 0.3577 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3587 - categorical_accuracy: 1.0000 - val_loss: 0.3390 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3393 - categorical_accuracy: 1.0000 - val_loss: 0.3205 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3186 - categorical_accuracy: 1.0000 - val_loss: 0.3020 - val_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 75ms/step\n",
      "loss: 0.644661068916\n",
      "categorical_accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "cnn_model = keras.models.load_model('model-conv1d.h5')\n",
    "metrics = cnn_model.evaluate(x_test, y_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
