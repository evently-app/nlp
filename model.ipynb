{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json\n",
    "import keras\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the category file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category file contains all category classes we designed. Right now they are \"concerts\",\n",
    " \"sports\",\n",
    " \"shows\",\n",
    " \"comedy\",\n",
    " \"art\",\n",
    " \"nightlife\",\n",
    " \"family\",\n",
    " and \"professional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Concerts', u'Sports', u'Shows', u'Comedy', u'Art', u'Nightlife', u'Family', u'Professional', u'Food&Drink']\n"
     ]
    }
   ],
   "source": [
    "with open(\"categories.json\",\"r\") as fp:\n",
    "    categories = json.load(fp)\n",
    "print categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode event label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with events with single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'Art', u'Comedy', u'Concerts', u'Family', u'Food&Drink',\n",
       "       u'Nightlife', u'Professional', u'Shows', u'Sports'], dtype='<U12')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pangbo/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'Art'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform([0,1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Food&Drink', u'Professional', u'Food&Drink', u'Sports', u'Shows', u'Sports', u'Food&Drink', u'Food&Drink', u'Food&Drink', u'Professional', u'Family', u'Art', u'Professional', u'Nightlife', u'Sports', u'Food&Drink', u'Shows', u'Shows', u'Shows', u'Shows', u'Professional', u'Shows', u'Professional', u'Professional', u'Professional', u'Art', u'Professional', u'Nightlife', u'Shows']\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"LabeledEvent.json\",\"r\") as fp:\n",
    "    train = json.load(fp)\n",
    "x = [event['description']+\" \"+event['title'] for event in train if 'description' in event and 'title' in event]\n",
    "y = [event['primaryCategory'] for event in train if 'primaryCategory' in event]\n",
    "print y\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(categories)\n",
    "encoded_y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(encoded_y)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with event with multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'concerts', u'art'], [u'art']]\n",
      "[[1 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "# with open(\"train_fake_multiLabel.json\",\"r\") as fp:\n",
    "#     train = json.load(fp)\n",
    "# x = [event['text'] for event in train]\n",
    "# y = [event['category'] for event in train]\n",
    "# print y\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# y = mlb.fit_transform(y)\n",
    "# print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize event text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "x = pad_sequences(sequences, maxlen=180, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_length = 300\n",
    "max_words = 5000\n",
    "num_classes = len(y[0])\n",
    "maxlen = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 180, 20)           100000    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 180, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 178, 300)          18300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 2709      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 121,009\n",
      "Trainable params: 121,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20 samples, validate on 3 samples\n",
      "Epoch 1/20\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.6924 - categorical_accuracy: 0.0500 - val_loss: 0.6872 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 959us/step - loss: 0.6864 - categorical_accuracy: 0.0500 - val_loss: 0.6807 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6787 - categorical_accuracy: 0.2000 - val_loss: 0.6742 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6709 - categorical_accuracy: 0.5000 - val_loss: 0.6678 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6627 - categorical_accuracy: 0.6000 - val_loss: 0.6613 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6553 - categorical_accuracy: 0.6500 - val_loss: 0.6549 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6471 - categorical_accuracy: 0.6500 - val_loss: 0.6484 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6389 - categorical_accuracy: 0.6000 - val_loss: 0.6418 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6303 - categorical_accuracy: 0.7000 - val_loss: 0.6351 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6220 - categorical_accuracy: 0.8500 - val_loss: 0.6282 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6141 - categorical_accuracy: 0.7000 - val_loss: 0.6212 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6051 - categorical_accuracy: 0.8500 - val_loss: 0.6141 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5960 - categorical_accuracy: 0.8000 - val_loss: 0.6068 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5868 - categorical_accuracy: 0.9000 - val_loss: 0.5992 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5775 - categorical_accuracy: 0.8500 - val_loss: 0.5914 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5678 - categorical_accuracy: 0.9000 - val_loss: 0.5834 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5577 - categorical_accuracy: 0.9000 - val_loss: 0.5751 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5474 - categorical_accuracy: 0.9000 - val_loss: 0.5666 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5375 - categorical_accuracy: 0.9500 - val_loss: 0.5579 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5260 - categorical_accuracy: 0.9500 - val_loss: 0.5490 - val_categorical_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 502us/step\n",
      "loss: 0.543176949024\n",
      "categorical_accuracy: 0.333333343267\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "metrics = model.evaluate(x_test, y_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ynew = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3857464 , 0.37086114, 0.39092505, 0.3832836 , 0.4091908 ,\n",
       "        0.38083246, 0.40811855, 0.4004858 , 0.40568805],\n",
       "       [0.3952547 , 0.37878373, 0.39688212, 0.39079547, 0.4161353 ,\n",
       "        0.3832267 , 0.4098271 , 0.40636238, 0.40636778],\n",
       "       [0.38985646, 0.38089186, 0.38993537, 0.39470503, 0.40452087,\n",
       "        0.38208658, 0.41737264, 0.40877762, 0.40727186],\n",
       "       [0.3871193 , 0.37060234, 0.391263  , 0.383628  , 0.40789235,\n",
       "        0.37278503, 0.40518707, 0.39926824, 0.40043935],\n",
       "       [0.37926745, 0.3645649 , 0.38463914, 0.38096705, 0.40286848,\n",
       "        0.37256235, 0.40008447, 0.39397794, 0.3967126 ],\n",
       "       [0.3915453 , 0.38214314, 0.3936375 , 0.39702645, 0.40503457,\n",
       "        0.3832752 , 0.41460523, 0.40787268, 0.40843552]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 2, 2, 4, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
