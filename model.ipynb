{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the category file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category file contains all category classes we designed. Right now they are \"concerts\",\n",
    " \"sports\",\n",
    " \"shows\",\n",
    " \"comedy\",\n",
    " \"art\",\n",
    " \"nightlife\",\n",
    " \"family\",\n",
    " and \"professional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'concerts', u'sports', u'shows', u'comedy', u'art', u'nightlife', u'family', u'professional', u'food&drink']\n"
     ]
    }
   ],
   "source": [
    "with open(\"categories.json\",\"r\") as fp:\n",
    "    categories = json.load(fp)\n",
    "print categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode event label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with events with single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Food&Drink', u'Professional', u'Food&Drink', u'Sports', u'Shows', u'Sports', u'Food&Drink', u'Food&Drink', u'Food&Drink', u'Professional', u'Family', u'Art', u'Professional', u'Nightlife', u'Sports', u'Food&Drink', u'Shows', u'Shows', u'Shows', u'Shows', u'Professional', u'Shows', u'Professional', u'Professional', u'Professional', u'Art', u'Professional', u'Nightlife', u'Shows']\n",
      "[[0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"LabeledEvent.json\",\"r\") as fp:\n",
    "    train = json.load(fp)\n",
    "x = [event['description']+\" \"+event['title'] for event in train if 'description' in event and 'title' in event]\n",
    "y = [event['primaryCategory'] for event in train if 'primaryCategory' in event]\n",
    "print y\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(encoded_y)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with event with multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'concerts', u'art'], [u'art']]\n",
      "[[1 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_fake_multiLabel.json\",\"r\") as fp:\n",
    "    train = json.load(fp)\n",
    "x = [event['text'] for event in train]\n",
    "y = [event['category'] for event in train]\n",
    "print y\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize event text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "x = pad_sequences(sequences, maxlen=180, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_length = 300\n",
    "max_words = 5000\n",
    "num_classes = len(y[0])\n",
    "maxlen = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pangbo/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/pangbo/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 180, 20)           100000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 180, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 178, 300)          18300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 2107      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 120,407\n",
      "Trainable params: 120,407\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/pangbo/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/pangbo/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 20 samples, validate on 3 samples\n",
      "Epoch 1/20\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.6923 - categorical_accuracy: 0.1000 - val_loss: 0.6858 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6843 - categorical_accuracy: 0.2500 - val_loss: 0.6791 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6757 - categorical_accuracy: 0.3000 - val_loss: 0.6725 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6678 - categorical_accuracy: 0.3000 - val_loss: 0.6659 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6596 - categorical_accuracy: 0.3000 - val_loss: 0.6593 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6518 - categorical_accuracy: 0.3000 - val_loss: 0.6527 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6430 - categorical_accuracy: 0.3500 - val_loss: 0.6460 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6350 - categorical_accuracy: 0.3500 - val_loss: 0.6395 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6272 - categorical_accuracy: 0.3500 - val_loss: 0.6328 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6188 - categorical_accuracy: 0.4000 - val_loss: 0.6260 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6103 - categorical_accuracy: 0.4000 - val_loss: 0.6192 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6014 - categorical_accuracy: 0.4500 - val_loss: 0.6122 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5927 - categorical_accuracy: 0.4000 - val_loss: 0.6051 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5838 - categorical_accuracy: 0.5000 - val_loss: 0.5979 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5750 - categorical_accuracy: 0.4500 - val_loss: 0.5906 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5656 - categorical_accuracy: 0.5000 - val_loss: 0.5832 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5563 - categorical_accuracy: 0.5000 - val_loss: 0.5756 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5473 - categorical_accuracy: 0.7000 - val_loss: 0.5680 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5373 - categorical_accuracy: 0.5500 - val_loss: 0.5603 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5272 - categorical_accuracy: 0.7000 - val_loss: 0.5526 - val_categorical_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 13ms/step\n",
      "loss: 0.544360339642\n",
      "categorical_accuracy: 0.333333343267\n"
     ]
    }
   ],
   "source": [
    "cnn_model = keras.models.load_model('model-conv1d.h5')\n",
    "metrics = cnn_model.evaluate(x_test, y_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ynew = cnn_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38057137, 0.37495065, 0.38566658, 0.36116973, 0.37529027,\n",
       "        0.4082635 , 0.3800807 ],\n",
       "       [0.3855164 , 0.37498653, 0.38796788, 0.36193812, 0.38027138,\n",
       "        0.40841955, 0.38636413],\n",
       "       [0.38745114, 0.37520587, 0.38530108, 0.36852673, 0.37690982,\n",
       "        0.39931256, 0.37685555],\n",
       "       [0.37637684, 0.37080765, 0.38281313, 0.35633585, 0.3722051 ,\n",
       "        0.40155664, 0.37588236],\n",
       "       [0.37531966, 0.36577433, 0.3820672 , 0.34968072, 0.36579782,\n",
       "        0.39559516, 0.3784711 ],\n",
       "       [0.39060193, 0.3876232 , 0.39640853, 0.37898305, 0.38716996,\n",
       "        0.40427104, 0.38655668]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
